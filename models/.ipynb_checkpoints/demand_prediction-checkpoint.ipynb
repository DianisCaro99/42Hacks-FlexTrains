{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1215f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import plotly.express as px\n",
    "import enlighten\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "## let's try use pytorch \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cdc9ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43ced7f",
   "metadata": {},
   "source": [
    "## first we preprocess the data, we separate by hour and tokenize the stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79d00dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand=pd.read_csv('./../generated_demand/demand_100000.csv')\n",
    "\n",
    "X=np.zeros((demand.shape[0],3))\n",
    "X[:,0]=demand['Lat'].to_numpy()\n",
    "X[:,1]=demand['Lon'].to_numpy()\n",
    "X[:,2]=demand['time_for_walk'].map(lambda x: x.hour)\n",
    "#now we tokenize \n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer2 = CountVectorizer()\n",
    "Tokens = vectorizer.fit_transform(demand['id_busStop'])\n",
    "d = dict([(y,x) for x,y in enumerate(sorted(set(demand['id_TrainStation'])))])\n",
    "Y=demand['id_TrainStation'].map(lambda x: d[x]).to_numpy()\n",
    "#to know the tokenization \n",
    "#features = vectorizer.get_feature_names()\n",
    "X_encoded=np.concatenate((X, Tokens.toarray()), axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,random_state=0)\n",
    "x_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.FloatTensor(Y_train).type(torch.LongTensor)\n",
    "x_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.FloatTensor(Y_test).type(torch.LongTensor)\n",
    "# Now in the format they want \n",
    "train_data=[]\n",
    "for i in range(x_train.shape[0]):\n",
    "    train_data.append((x_train[i],y_train[i]))\n",
    "\n",
    "#test data\n",
    "test_data=[]\n",
    "for i in range(x_test.shape[0]):\n",
    "    test_data.append((x_test[i],y_test[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5000414",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator = data.DataLoader(train_data, \n",
    "                                 shuffle = True, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(test_data, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "test_iterator = data.DataLoader(test_data, \n",
    "                                batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428001a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14b34e96",
   "metadata": {},
   "source": [
    "## Now we train the NN mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e7e4278",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.input_fc = nn.Linear(input_dim, 250)\n",
    "        self.hidden_fc = nn.Linear(250, 100)\n",
    "        self.output_fc = nn.Linear(100, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = [batch size, height, width]\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = x.view(batch_size, -1)\n",
    "        \n",
    "        #x = [batch size, height * width]\n",
    "        \n",
    "        h_1 = F.relu(self.input_fc(x))\n",
    "        \n",
    "        #h_1 = [batch size, 250]\n",
    "\n",
    "        h_2 = F.relu(self.hidden_fc(h_1))\n",
    "\n",
    "        #h_2 = [batch size, 100]\n",
    "\n",
    "        y_pred = self.output_fc(h_2)\n",
    "        \n",
    "        #y_pred = [batch size, output dim]\n",
    "        \n",
    "        return y_pred, h_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4aeb2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 54\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = X.shape[1]\n",
    "OUTPUT_DIM = max(d.values())+1\n",
    "print(INPUT_DIM,OUTPUT_DIM )\n",
    "model = MLP(INPUT_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2278565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 31,554 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f7adbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "636d7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "032e8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (x, y) in iterator:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred, _ = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c60bebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c421edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4acb0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.283 | Train Acc: 80.23%\n",
      "\t Val. Loss: 1.296 |  Val. Acc: 80.02%\n",
      "Epoch: 02 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.283 | Train Acc: 80.23%\n",
      "\t Val. Loss: 1.294 |  Val. Acc: 80.02%\n",
      "Epoch: 03 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.283 | Train Acc: 80.23%\n",
      "\t Val. Loss: 1.294 |  Val. Acc: 80.02%\n",
      "Epoch: 04 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.283 | Train Acc: 80.23%\n",
      "\t Val. Loss: 1.294 |  Val. Acc: 80.02%\n",
      "Epoch: 05 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.283 | Train Acc: 80.23%\n",
      "\t Val. Loss: 1.294 |  Val. Acc: 80.02%\n",
      "Epoch: 06 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.283 | Train Acc: 80.23%\n",
      "\t Val. Loss: 1.294 |  Val. Acc: 80.02%\n",
      "Epoch: 07 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.283 | Train Acc: 80.23%\n",
      "\t Val. Loss: 1.294 |  Val. Acc: 80.02%\n",
      "Epoch: 08 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.283 | Train Acc: 80.23%\n",
      "\t Val. Loss: 1.294 |  Val. Acc: 80.02%\n",
      "Epoch: 09 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.283 | Train Acc: 80.23%\n",
      "\t Val. Loss: 1.294 |  Val. Acc: 80.02%\n",
      "Epoch: 10 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.283 | Train Acc: 80.23%\n",
      "\t Val. Loss: 1.294 |  Val. Acc: 80.02%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a9d39",
   "metadata": {},
   "source": [
    "## Now we test the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e74b295",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6n/sk641xl577dft6gb31xzm8nh0000gn/T/ipykernel_5828/1065996699.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand['time_for_walk'].map(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c5e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(demand['id_busStop'])\n",
    "features = vectorizer.get_feature_names()\n",
    "print(X.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ea02f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f237258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92422908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
